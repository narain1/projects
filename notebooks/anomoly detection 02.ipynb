{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a4d73d-f71f-48b1-b924-5735f99805f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa as lb\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from typing import Optional, Union, Tuple\n",
    "from fastcore.all import *\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from timm import create_model\n",
    "# from fastai.vision.all import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from nnAudio import features\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import kornia as K\n",
    "import fastprogress\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfbb62d-6075-4d4a-8d00-20a8bb53fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47600139-852b-4a6b-8ae6-b1a805b7d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/data/fan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49bc8611-ffa9-474f-a45a-ea3ea91952d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ext = lambda x: [i for i,j in mimetypes.types_map.items() if j.startswith(x)]\n",
    "\n",
    "image_ext = get_ext('image')\n",
    "video_ext = get_ext('video')\n",
    "text_ext = get_ext('text')\n",
    "audio_ext = get_ext('audio')\n",
    "\n",
    "join_path = lambda x, y: Path(os.path.join(x, y))\n",
    "\n",
    "def get_files(root: Union[str, Path], \n",
    "        file_type: Union[str, Tuple[str, ...]]=None,\n",
    "        recursive: Optional[bool]=True, \n",
    "        generator: Optional[bool]=False):\n",
    "    files = []\n",
    "    if file_type: file_type = tuple(file_type)\n",
    "    if not recursive:\n",
    "        files.extend([join_path(root, i) for i in \n",
    "            os.listdir(root) if str(i).lower().endswith(file_type)])\n",
    "    else:\n",
    "        for p, d, fs in os.walk(root):\n",
    "            if file_type:\n",
    "                files.extend([join_path(p, f) for f in fs if str(f).lower().endswith(file_type)])\n",
    "            else:\n",
    "                files.extend([join_path(p, f) for f in fs])\n",
    "    return L(files) if bool else iter(files)\n",
    "\n",
    "\n",
    "get_image_files = partial(get_files, file_type= image_ext)\n",
    "get_video_files = partial(get_files, file_type= video_ext)\n",
    "get_text_files = partial(get_files, file_type= text_ext)\n",
    "get_audio_files = partial(get_files, file_type= audio_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53bc2df-19b7-42ef-b959-c19b40b412a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = get_audio_files(data_path)\n",
    "normal_fs = fs.filter(lambda x: x.parent.name=='normal')\n",
    "abnormal_fs = fs.filter(lambda x: x.parent.name=='abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2461849f-6839-43b0-b98d-32ff4ad038dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = file_load(fs[1])\n",
    "# out[0].shape, out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e224f5-f0e8-4dfe-9cb7-9b89e3a4fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_load(wav_name, mono=False):\n",
    "    return lb.load(wav_name, sr=None, mono=mono)\n",
    "\n",
    "def demux_wav(wav_name, channel=0):\n",
    "    multi_channel_data, sr = file_load(wav_name)\n",
    "    if multi_channel_data.ndim <= 1: return sr, multi_channel_data\n",
    "    return sr, np.array(multi_channel_data)[channel, :]\n",
    "\n",
    "def file_to_vector_array(file_name,\n",
    "                         n_mels=64,\n",
    "                         frames=5,\n",
    "                         n_fft=1024,\n",
    "                         hop_length=512,\n",
    "                         power=2.0):\n",
    "    # 01 calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # 02 generate melspectrogram using librosa (**kwargs == param[\"librosa\"])\n",
    "    sr, y = demux_wav(file_name)\n",
    "    mel_spectrogram = lb.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "\n",
    "    # 03 convert melspectrogram to log mel energy\n",
    "    log_mel_spectrogram = 20.0 / power * np.log10(mel_spectrogram + sys.float_info.epsilon)\n",
    "\n",
    "    # 04 calculate total vector size\n",
    "    vectorarray_size = len(log_mel_spectrogram[0, :]) - frames + 1\n",
    "\n",
    "    # 05 skip too short clips\n",
    "    if vectorarray_size < 1:\n",
    "        return np.empty((0, dims), float)\n",
    "\n",
    "    # 06 generate feature vectors by concatenating multi_frames\n",
    "    vectorarray = np.zeros((vectorarray_size, dims), float)\n",
    "    for t in range(frames):\n",
    "        vectorarray[:, n_mels * t: n_mels * (t + 1)] = log_mel_spectrogram[:, t: t + vectorarray_size].T\n",
    "\n",
    "    return vectorarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77763166-4bd1-4861-bddb-ba84f22f99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_vector_array(file_list,\n",
    "                         msg=\"calc...\",\n",
    "                         n_mels=64,\n",
    "                         frames=5,\n",
    "                         n_fft=1024,\n",
    "                         hop_length=512,\n",
    "                         power=2.0):\n",
    "    # 01 calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # 02 loop of file_to_vectorarray\n",
    "    for idx in range(len(file_list)):\n",
    "\n",
    "        vector_array = file_to_vector_array(file_list[idx],\n",
    "                                            n_mels=n_mels,\n",
    "                                            frames=frames,\n",
    "                                            n_fft=n_fft,\n",
    "                                            hop_length=hop_length,\n",
    "                                            power=power)\n",
    "\n",
    "        if idx == 0:\n",
    "            dataset = np.zeros((vector_array.shape[0] * len(file_list), dims), float)\n",
    "\n",
    "        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array\n",
    "\n",
    "    return torch.tensor(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "101bea56-86dc-4238-8f68-33884b34da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(idno):\n",
    "    fs = get_audio_files(os.path.join('/home/ubuntu/data/fan', idno))\n",
    "    normal_fs = fs.filter(lambda x: x.parent.name=='normal')\n",
    "    abnormal_fs = fs.filter(lambda x: x.parent.name=='abnormal')\n",
    "    train_fs, val_fs = train_test_split(normal_fs)\n",
    "    train_ds = list_to_vector_array(train_fs)\n",
    "    val_ds = list_to_vector_array(val_fs)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=512, shuffle=True, pin_memory=True, num_workers=4, drop_last=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=512, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    return train_dl, val_dl, val_fs, abnormal_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc00b720-ba5f-4e5c-bf43-6b6614de6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(fold, normal=True):\n",
    "    kf = StratifiedKFold(5, random_state=13, shuffle=True)\n",
    "    fs = get_audio_files(data_path)\n",
    "    fs = fs.filter(lambda x: x.parent.name=='normal' if normal else 'abnormal')\n",
    "    for k, (train_ids, val_ids) in enumerate(kf.split(fs, fs.map(lambda x: x.parent.name))):\n",
    "        if k == fold: return SpecDataset(fs[train_ids]), SpecDataset(fs[val_ids])\n",
    "    \n",
    "def get_test_dl():\n",
    "    fs = get_audio_files(data_path)\n",
    "    fs = fs.filter(lambda x: x.parent.name=='abnormal')\n",
    "    return DataLoader(SpecDataset(fs), bs=512, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b3cdd2-789b-440a-9051-7097eacb37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vae_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.BatchNorm1d(320),\n",
    "        nn.Linear(320, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 320)).cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c7720c7-c884-48e7-a7a0-981496171fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PreProcCB(Callback):\n",
    "#     def before_batch(self):\n",
    "#         self.learn.xb = (self.xb[0].view(-1, 320).float(),)\n",
    "#         self.learn.yb = (self.yb[0].view(-1, 320).float(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8333e1e8-1de2-4c3f-85bf-505c6c56333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 161.30498465429793 13.61529929774582\n",
      "20 5.445146947652421 5.343599565469535\n",
      "40 5.381173160397776 5.343428985328432\n",
      "60 5.318396388590974 5.21998676980377\n",
      "80 5.266455416505801 5.173883231582155\n",
      "(array([False,  True]), array([298, 309]))\n",
      "id_04 0.8620523012097913\n",
      "0 158.9797907311932 14.380617791956121\n",
      "20 4.844856436735665 4.75005546173492\n",
      "40 4.661952157945155 4.5753401533349765\n",
      "60 4.547903000659153 4.46207020809124\n",
      "80 4.503927725332755 4.4515147518802\n",
      "(array([False,  True]), array([238, 377]))\n",
      "id_06 0.9787798408488064\n",
      "0 144.46146346281296 11.108984581835859\n",
      "20 5.371012775986283 5.41124127437542\n",
      "40 5.283383234393883 5.3019843968478115\n",
      "60 5.234140309892709 5.234001729395483\n",
      "80 5.2149799934919105 5.210710033193811\n",
      "(array([False,  True]), array([239, 374]))\n",
      "id_02 0.9799465240641712\n",
      "0 196.66892580495622 20.686363955728368\n",
      "20 5.685819026938674 5.571377810309915\n",
      "40 5.54637345808601 5.490440346836265\n",
      "60 5.450759505808223 5.384240602356156\n",
      "80 5.4021585253709254 5.329593848558813\n",
      "(array([False,  True]), array([493, 167]))\n",
      "id_00 0.6644034446320342\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "data_path = '/home/ubuntu/data/fan'\n",
    "stat_dict = dict()\n",
    "for idno in os.listdir(data_path):\n",
    "# for idno in ['id_00']:\n",
    "    train_dl, val_dl, val_fs, abnormal_fs = get_dataloader(idno)\n",
    "    model = get_vae_model()\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        train_acc, val_acc = [], []\n",
    "        model.train()\n",
    "        for k, (xb) in enumerate(train_dl):\n",
    "            xb = xb.T.flatten(1).T.float().cuda()\n",
    "            pred = model(xb)\n",
    "            loss = F.mse_loss(pred, xb)\n",
    "            train_acc.append(loss.mean().item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for k, (xb) in enumerate(val_dl):\n",
    "                xb = xb.T.flatten(1).T.float().cuda()\n",
    "                pred = model(xb)\n",
    "                loss = F.mse_loss(pred, xb)\n",
    "                val_acc.append(loss.mean().item())\n",
    "        if epoch % 20 == 0: print(epoch, np.array(train_acc).mean(), np.array(val_acc).mean())\n",
    "        \n",
    "    val_acc = []\n",
    "    for item in val_fs:\n",
    "        inp = torch.from_numpy(file_to_vector_array(item)).cuda().float()\n",
    "        val_acc.append(torch.mean(torch.square(inp - model(inp)), axis=1).mean().item())\n",
    "    val_acc = np.array(val_acc)\n",
    "    \n",
    "    abnormal_acc = []\n",
    "    for item in abnormal_fs:\n",
    "        inp = torch.from_numpy(file_to_vector_array(item)).cuda().float()\n",
    "        abnormal_acc.append(torch.mean(torch.square(inp - model(inp)), axis=1).mean().item())\n",
    "    \n",
    "    abnormal_acc = np.array(abnormal_acc)\n",
    "    normal_vals, normal_targets = np.abs(val_acc - val_acc.mean())/val_acc.std(), np.zeros_like(val_acc)\n",
    "    abnormal_vals, abnormal_targets = np.abs(abnormal_acc - val_acc.mean())/val_acc.std(), np.ones_like(abnormal_acc)\n",
    "    stat_dict[idno] = {'mean': val_acc.mean(), 'std': val_acc.std(), 'normal_mean': normal_vals.mean(), 'normal_std': normal_vals.std()}\n",
    "    print(np.unique(np.concatenate([normal_vals, abnormal_vals]) > normal_vals.mean() + normal_vals.std(), return_counts=True))\n",
    "    print(idno, roc_auc_score(np.concatenate([normal_vals, abnormal_vals]) > normal_vals.mean() + normal_vals.std(), \n",
    "                              np.concatenate([normal_targets, abnormal_targets])))\n",
    "    torch.save(model.state_dict(), f'model_{idno}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b024ae73-e39c-44f6-9c62-c63453bca9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('model_stats.json', 'w+') as f_out:\n",
    "    json.dump(stat_dict, f_out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f744013-4d60-41bf-b519-3384ba3db29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_stats.json', 'r+') as f_in:\n",
    "    stat_dict = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f26918-0965-4f02-acbd-1d0c96ee6786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_04': {'mean': 5.140185948964712,\n",
       "  'std': 0.3677342813898396,\n",
       "  'normal_mean': 0.7545354805163678,\n",
       "  'normal_std': 0.6562592541381294},\n",
       " 'id_06': {'mean': 4.413740190934009,\n",
       "  'std': 0.4748257903047574,\n",
       "  'normal_mean': 0.6879852254030572,\n",
       "  'normal_std': 0.7257246927224571},\n",
       " 'id_02': {'mean': 5.199724843182902,\n",
       "  'std': 0.27132566890592325,\n",
       "  'normal_mean': 0.7260894119648542,\n",
       "  'normal_std': 0.6876002951079446},\n",
       " 'id_00': {'mean': 5.33057733392527,\n",
       "  'std': 0.821168818417859,\n",
       "  'normal_mean': 0.6635359707191701,\n",
       "  'normal_std': 0.748144381494487}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f026ef4f-2640-4742-8480-aa616e4ad163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(machine_id):\n",
    "    m = get_vae_model()\n",
    "    m.load_state_dict(torch.load(f'model_{machine_id}.pth'))\n",
    "    m = m.eval()\n",
    "    m = m.float()\n",
    "    m = m.cuda()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c997b027-2c24-4f93-b0d6-05e5ba7c9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {i: load_weights(i) for i in sorted(os.listdir(data_path))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6de596dd-31b5-4418-ab1b-ea17c306c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(machine_number, file_name):\n",
    "    inp = torch.from_numpy(file_to_vector_array(file_name)).cuda().float()\n",
    "    prediction_map = {True: 'abnormal', False: 'normal'}\n",
    "    return prediction_map[abs(torch.mean(torch.square(inp - models[machine_number](inp)), axis=1).mean().item() - \n",
    "               stat_dict[machine_number]['mean'])/stat_dict[machine_number]['std'] > \n",
    "                          stat_dict[machine_number]['normal_mean'] + stat_dict[machine_number]['normal_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f31d8412-e7e0-46d3-8387-4ad86c91720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5550) [Path('/home/ubuntu/data/fan/id_04/normal/00000456.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000667.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000300.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000989.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000047.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000362.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000801.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000417.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000043.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000648.wav')...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "276aa388-44bb-498c-9776-c025af960925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 1011, 'abnormal': 407})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(fs.filter(lambda x: x.parent.parent.name == \"id_00\").map(lambda x: x.parent.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23b7921a-5820-4a1e-8e6e-00da6b108286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 1197, 'abnormal': 221})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "acc_00 = [predict('id_00', o)  for o in fs.filter(lambda x: x.parent.parent.name == \"id_00\")]\n",
    "Counter(acc_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b562a51e-fc40-42e9-bd0c-2d7fa07104dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 1016, 'abnormal': 359})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(fs.filter(lambda x: x.parent.parent.name == \"id_02\").map(lambda x: x.parent.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7a48c14-9e46-4537-9176-664735a9055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 940, 'abnormal': 435})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_02 = [predict('id_02', o)  for o in fs.filter(lambda x: x.parent.parent.name == \"id_02\")]\n",
    "Counter(acc_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01f81b80-8b73-4c44-95a2-779b41cd72d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 1033, 'abnormal': 348})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(fs.filter(lambda x: x.parent.parent.name == \"id_04\").map(lambda x: x.parent.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b524c8f-d033-4d7c-b468-589bd16b8740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 984, 'abnormal': 397})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_04 = [predict('id_04', o)  for o in fs.filter(lambda x: x.parent.parent.name == \"id_04\")]\n",
    "Counter(acc_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b4ed7a5-3428-4e43-86af-9ce6d47e91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 1015, 'abnormal': 361})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(fs.filter(lambda x: x.parent.parent.name == \"id_06\").map(lambda x: x.parent.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf34c71-1beb-48cd-8020-d0193ae650c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 924, 'abnormal': 452})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_06 = [predict('id_06', o)  for o in fs.filter(lambda x: x.parent.parent.name == \"id_06\")]\n",
    "Counter(acc_06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2611aa80-b8e3-462b-9fa8-7777a97506c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5550) [Path('/home/ubuntu/data/fan/id_04/normal/00000456.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000667.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000300.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000989.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000047.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000362.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000801.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000417.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000043.wav'),Path('/home/ubuntu/data/fan/id_04/normal/00000648.wav')...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9517664d-63c0-4057-98e8-69165afc5aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal': 1011, 'abnormal': 407})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(fs.filter(lambda x: x.parent.parent.name == 'id_00').map(lambda x: x.parent.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61545720-8182-4f9f-a831-8a69f4706a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21672/1497762662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_fs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_to_vector_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_fs' is not defined"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "for item in train_fs:\n",
    "    inp = torch.from_numpy(file_to_vector_array(item)).cuda().float()\n",
    "    train_acc.append(torch.mean(torch.square(inp - model(inp)), axis=1).mean().item())\n",
    "\n",
    "train_acc = np.array(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d2871202-372e-41fc-a93d-327a113c27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = []\n",
    "for item in val_fs:\n",
    "    inp = torch.from_numpy(file_to_vector_array(item)).cuda().float()\n",
    "    val_acc.append(torch.mean(torch.square(inp - model(inp)), axis=1).mean().item())\n",
    "    \n",
    "val_acc = np.array(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f855259-752b-473e-8592-5b65764a135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_acc = []\n",
    "for item in abnormal_fs:\n",
    "    inp = torch.from_numpy(file_to_vector_array(item)).cuda().float()\n",
    "    abnormal_acc.append(torch.mean(torch.square(inp - model(inp)), axis=1).mean().item())\n",
    "    \n",
    "abnormal_acc = np.array(abnormal_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19176f-d8b3-48c7-bd68-3f5b8f10c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc.mean(), train_acc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5012962d-6053-4cae-bdfc-f139d74a35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc.mean(), val_acc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441f54f-f9d7-487b-b12e-b4c7330a83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_acc.mean(), abnormal_acc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a7c74-7741-4554-80fe-795ab295b028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adfa9b-cf84-4019-ad52-9cc805779242",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_vals, normal_targets = np.abs(val_acc - val_acc.mean())/val_acc.std(), np.zeros_like(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3ab59-2e66-4eeb-983e-c801511151e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_vals, abnormal_targets = np.abs(abnormal_acc - val_acc.mean())/val_acc.std(), np.ones_like(abnormal_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d635c6-d70a-4cdc-bdee-1da4d90ad7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(np.concatenate([normal_vals, abnormal_vals]) > normal_vals.mean() + normal_vals.std(), np.concatenate([normal_targets, abnormal_targets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7884359-c352-47e6-87cd-c2032965cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e418d01b-8637-4969-996d-f61a9257dbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([137.,  84.,  12.,  50.,  20.,   9.,  21.,  12.,  11.,   3.]),\n",
       " array([ 1.45368495,  5.8904534 , 10.32722186, 14.76399032, 19.20075878,\n",
       "        23.63752723, 28.07429569, 32.51106415, 36.9478326 , 41.38460106,\n",
       "        45.82136952]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normal_vals)\n",
    "plt.hist(abnormal_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281524c3-eff0-4254-8aff-2ca2a1f43b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
